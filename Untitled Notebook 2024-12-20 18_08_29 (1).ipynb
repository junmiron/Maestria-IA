{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0173bbe-2b32-4456-87ad-43bff1e4480d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_paths = \"/FileStore/annual_enterprise.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8bdf93d-080d-47bf-ae02-13030488b6f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category| Value|Industry_code_ANZSIC06|\n+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|930995|  ANZSIC06 division...|\n|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|821630|  ANZSIC06 division...|\n+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "file_paths = \"/FileStore/annual_enterprise.csv\"\n",
    "dataframe = spark.read.csv(file_paths, header=True, inferSchema=True)\n",
    "dataframe.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a8d4e73-aeff-4e09-8649-a0cc4e5b9340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Year: integer (nullable = true)\n |-- Industry_aggregation_NZSIOC: string (nullable = true)\n |-- Industry_code_NZSIOC: string (nullable = true)\n |-- Industry_name_NZSIOC: string (nullable = true)\n |-- Units: string (nullable = true)\n |-- Variable_code: string (nullable = true)\n |-- Variable_name: string (nullable = true)\n |-- Variable_category: string (nullable = true)\n |-- Value: string (nullable = true)\n |-- Industry_code_ANZSIC06: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5d288da-a3c5-4652-a4c7-6998551062c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------------+\n|       Variable_name|Year|             Units|\n+--------------------+----+------------------+\n|        Total income|2023|Dollars (millions)|\n|Sales, government...|2023|Dollars (millions)|\n|Interest, dividen...|2023|Dollars (millions)|\n+--------------------+----+------------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "subsample = dataframe.select('Variable_name', 'Year', 'Units')\n",
    "subsample.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06010d77-ef87-4d0c-962a-5e3f7cbaf185",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c58e6fee-ec64-446d-a842-f22339b2cef5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+------------------+\n|Variable_name|Year|             Units|\n+-------------+----+------------------+\n| Total income|2023|Dollars (millions)|\n| Total income|2023|Dollars (millions)|\n| Total income|2023|Dollars (millions)|\n| Total income|2023|Dollars (millions)|\n+-------------+----+------------------+\nonly showing top 4 rows\n\n"
     ]
    }
   ],
   "source": [
    "sampled_filtered = subsample.where(f.col('Variable_name') == 'Total income')\n",
    "sampled_filtered.show(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d1f713d-7245-4f18-8ba8-52f1be40055a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: 1529"
     ]
    }
   ],
   "source": [
    "sampled_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "837763b3-f03f-406c-8fcf-ae03e6512b97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: 50985"
     ]
    }
   ],
   "source": [
    "dataframe.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c4672807-0d03-4822-a99c-ea64a596882d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+------------------+\n|Variable_name|Year|             Units|\n+-------------+----+------------------+\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n+-------------+----+------------------+\nonly showing top 4 rows\n\n"
     ]
    }
   ],
   "source": [
    "sampled_filtered_2 = subsample.where((f.col('Variable_name') == 'Total income') & (f.col('Year') == 2019))\n",
    "sampled_filtered_2.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78858966-750f-4157-acd8-53363c5996d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataframe_grouped = dataframe.groupBy('Variable_name').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a596ab16-94cc-4636-acb6-d8677f25369b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n|       Variable_name|count|\n+--------------------+-----+\n|Surplus before in...| 1529|\n|        Other assets| 1474|\n|Sales of other go...|  572|\n+--------------------+-----+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframe_grouped.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d47d5e99-7b91-4896-9acb-fbc9e670bfde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3169496972694323>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mVariable_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mValue\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/group.py:49\u001B[0m, in \u001B[0;36mdf_varargs_api.<locals>._api\u001B[0;34m(self, *cols)\u001B[0m\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_api\u001B[39m(\u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGroupedData\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n",
       "\u001B[1;32m     48\u001B[0m     name \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n",
       "\u001B[0;32m---> 49\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jgd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: \"Value\" is not a numeric column. Aggregation function can only be applied on a numeric column."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\nFile \u001B[0;32m<command-3169496972694323>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdataframe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mVariable_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msum\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mValue\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshow()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/group.py:49\u001B[0m, in \u001B[0;36mdf_varargs_api.<locals>._api\u001B[0;34m(self, *cols)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_api\u001B[39m(\u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGroupedData\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39mcols: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame:\n\u001B[1;32m     48\u001B[0m     name \u001B[38;5;241m=\u001B[39m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[0;32m---> 49\u001B[0m     jdf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jgd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_to_seq\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DataFrame(jdf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:234\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    230\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\n\u001B[0;31mAnalysisException\u001B[0m: \"Value\" is not a numeric column. Aggregation function can only be applied on a numeric column.",
       "errorSummary": "<span class='ansi-red-fg'>AnalysisException</span>: \"Value\" is not a numeric column. Aggregation function can only be applied on a numeric column.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    ".groupBy('Variable_name').sum('Value').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ca1b9a2-72ff-435a-85dd-191e16756dec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n| Value|             Units|\n+------+------------------+\n|930995|Dollars (millions)|\n|821630|Dollars (millions)|\n+------+------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframe.select('Value', 'Units').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee293fb8-4814-49c5-a184-cdcdb271974e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, BooleanType, ArrayType\n",
    "\n",
    "dataframe = dataframe.withColumn('Value', f.col('Value').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b4c0dca-92b1-45f2-af9c-462d8f79bf3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n|       Variable_name|sum(Value)|\n+--------------------+----------+\n|Surplus before in...| 1805350.0|\n|        Other assets|1.924057E7|\n+--------------------+----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframe.groupBy('Variable_name').sum('Value').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b31d468-cef3-4e88-8cf4-27687b6081dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aggregated_table = dataframe.groupBy(\"Variable_name\").agg(\n",
    "    f.sum(\"Value\").alias(\"Sum\"),\n",
    "    f.mean(\"Value\").alias(\"Mean\"),\n",
    "    f.max(\"Value\").alias(\"Max\"),\n",
    "    f.count(\"Value\").alias(\"Count\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb33670a-030b-4e28-a2ab-f994df60a72e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "aggregated_table.createOrReplaceTempView('DatosAggregados')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb39c6d6-1964-4f4c-89ef-470e8a2ddbd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+---------+-----+\n|       Variable_name|       Sum|              Mean|      Max|Count|\n+--------------------+----------+------------------+---------+-----+\n|Surplus before in...| 1805350.0|1466.5718927701057| 124542.0| 1231|\n|        Other assets|1.924057E7|22141.047180667432|1288749.0|  869|\n+--------------------+----------+------------------+---------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"Select * from DatosAggregados LIMIT 10 \"\"\"\n",
    "spark.sql(query).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbec9a24-ea87-4be4-8317-d7652224bef2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataframe.createOrReplaceTempView('MainDataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9d0a088-3a11-43bf-bd19-962a3f7bc242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+------------------+\n|Variable_name|YearModified|             Units|\n+-------------+------------+------------------+\n| Total income|        2019|Dollars (millions)|\n| Total income|        2019|Dollars (millions)|\n+-------------+------------+------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query1 = \"\"\" SELECT  Variable_name, year AS YearModified, Units FROM MainDataset\n",
    "             WHERE Variable_name = 'Total income' and year=2019\n",
    "             LIMIT 10\n",
    "        \"\"\"\n",
    "\n",
    "spark.sql(query1).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b37140f7-e933-42ee-a280-ea67a8565063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+------------------+\n|Variable_name|Year|             Units|\n+-------------+----+------------------+\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n| Total income|2019|Dollars (millions)|\n+-------------+----+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "dataframe.select(\"Variable_name\", \"Year\", \"Units\").where(\n",
    "    (f.col(\"Variable_name\") == \"Total income\") & (f.col(\"year\") == 2019)\n",
    ").limit(10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a804076d-7e7e-4173-b46d-48250971a9a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf5e2332-cc29-4d21-820a-2d7395f24540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1) Load all datasets into the Databrick system\n",
    "2) Load the dataset into Spark SQL\n",
    "3) Create two subsamples with the most relevance characteristics (at least five).\n",
    "4) Concatenate the value of two columns\n",
    "5) Group By the elements by different columns and get the max, min, mean and count of one of the numerical values\n",
    "6) Filter by three conditions the number of rows\n",
    "7) Convert this dataset into Pandas (Search in google)\n",
    "8) Write the CSV using Pandas and PySpark (writing with Pandas is not feasible in databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c732dd32-fc31-447f-a89c-83c090420451",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|       Variable_name|   Variable_category| Value|Industry_code_ANZSIC06|\n+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\n|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H01|        Total income|Financial perform...|930995|  ANZSIC06 division...|\n|2023|                    Level 1|               99999|      All industries|Dollars (millions)|          H04|Sales, government...|Financial perform...|821630|  ANZSIC06 division...|\n+----+---------------------------+--------------------+--------------------+------------------+-------------+--------------------+--------------------+------+----------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "file_paths = \"/FileStore/annual_enterprise.csv\"\n",
    "dataframe = spark.read.csv(file_paths, header=True, inferSchema=True)\n",
    "dataframe.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5490840f-a9f5-4d94-b45e-6753594fb63e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+---------------------------+------+\n|Year|       Variable_name|             Units|Industry_aggregation_NZSIOC| Value|\n+----+--------------------+------------------+---------------------------+------+\n|2023|        Total income|Dollars (millions)|                    Level 1|930995|\n|2023|Sales, government...|Dollars (millions)|                    Level 1|821630|\n+----+--------------------+------------------+---------------------------+------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "sample_dataframe = dataframe.select('Year', 'Variable_name', 'Units', 'Industry_aggregation_NZSIOC',  'Value')\n",
    "sample_dataframe.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67f60299-be23-493e-b9cd-9acbe7a531ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------------+---------------------------+------+--------------------+\n|Year|       Variable_name|             Units|Industry_aggregation_NZSIOC| Value| columna_concatenada|\n+----+--------------------+------------------+---------------------------+------+--------------------+\n|2023|        Total income|Dollars (millions)|                    Level 1|930995|   2023@Total income|\n|2023|Sales, government...|Dollars (millions)|                    Level 1|821630|2023@Sales, gover...|\n+----+--------------------+------------------+---------------------------+------+--------------------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "sample_dataframe = sample_dataframe.withColumn('columna_concatenada' , f.concat(f.col('Year'), f.lit('@'), f.col('Variable_name')))\n",
    "sample_dataframe.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebce9629-de00-4213-8a7b-4b6d89807f5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Year: integer (nullable = true)\n |-- Variable_name: string (nullable = true)\n |-- Units: string (nullable = true)\n |-- Industry_aggregation_NZSIOC: string (nullable = true)\n |-- Value: string (nullable = true)\n |-- columna_concatenada: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "sample_dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c3efeaa-6fd2-4078-b902-4ca0d061c237",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_dataframe = sample_dataframe.withColumn('Value', f.col('Value').cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a840269-94c6-41de-a6b2-36db9cc1c255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------+-----+-------+-----+\n|Year|       Variable_name|   Max|  Min|    Avg|Count|\n+----+--------------------+------+-----+-------+-----+\n|2023|      Indirect taxes|7426.0|  0.0|  206.2|  125|\n|2018|Shareholders fund...| 949.0|119.0|524.375|   24|\n+----+--------------------+------+-----+-------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframe_grouped = sample_dataframe.groupBy('Year', 'Variable_name').agg(f.max('Value').alias('Max'), \n",
    "                                                                   f.min('Value').alias('Min'), \n",
    "                                                                   f.avg('Value').alias('Avg'),\n",
    "                                                                   f.count('Value').alias('Count'))\n",
    "dataframe_grouped.show(2)                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cdf48be-27d2-48f1-8efc-ae9a9a505047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+--------+----+------------------+-----+\n|Year| Variable_name|     Max| Min|               Avg|Count|\n+----+--------------+--------+----+------------------+-----+\n|2023|Indirect taxes|  7426.0| 0.0|             206.2|  125|\n|2023|Current assets|861255.0|94.0|24378.092307692306|  130|\n+----+--------------+--------+----+------------------+-----+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframe_grouped_filtered = dataframe_grouped.where((f.col('Year')==2023) & (f.col('Max')> 1000) & (f.col('Count')> 100))\n",
    "dataframe_grouped_filtered.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e66184f4-d7c8-4d6d-8016-15e3fbaa5b38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Gesti√≥n de Esquema de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98415e5c-4e1d-4638-b18b-5769197d16b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[86]: [['Ronal', 45, 'Valencia'], ['Ana', 25, 'Barcelona'], ['Maria', 38, 'Madrid']]"
     ]
    }
   ],
   "source": [
    "data = [[\"Ronal\", 45, \"Valencia\"],\n",
    "        [\"Ana\", 25, \"Barcelona\"],\n",
    "        [\"Maria\", 38, \"Madrid\"]\n",
    "]\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bda3862-7e7d-4bd7-a610-a4146579e2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------+\n|Nombre|Edad|   Ciudad|\n+------+----+---------+\n| Ronal|  45| Valencia|\n|   Ana|  25|Barcelona|\n| Maria|  38|   Madrid|\n+------+----+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType, StringType, BooleanType, ArrayType, StructField, StructType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"Nombre\", StringType(), False), \n",
    "    StructField(\"Edad\", IntegerType(), False), \n",
    "    StructField(\"Ciudad\", StringType(), False)\n",
    "])\n",
    "\n",
    "new_dataframe = spark.createDataFrame(data, schema=schema)\n",
    "new_dataframe.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc9e68fc-576b-46f3-a848-136d14c1bae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Nombre: string (nullable = false)\n |-- Edad: integer (nullable = false)\n |-- Ciudad: string (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "new_dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "591a5023-89f4-44ef-93a9-3eb6c64f6dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "email_path = \"/FileStore/email.csv\"\n",
    "dataset_path = \"/FileStore/username_password_recovery_code.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "025c0e6a-f09a-46dd-a23e-1902dbb4afdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "email_df = spark.read.csv(email_path, inferSchema=True, header=True, sep=\";\")\n",
    "dataset_df = spark.read.csv(dataset_path, inferSchema=True, header=True, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76d68734-7dd4-47a0-8ff4-89ecf1ebc477",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+-----------+\n|    Login email_y|Identifier|First name_y|Last name_y|\n+-----------------+----------+------------+-----------+\n|laura@example.com|      2070|       Laura|       Grey|\n|craig@example.com|      4081|       Craig|    Johnson|\n+-----------------+----------+------------+-----------+\nonly showing top 2 rows\n\n+--------+-----------+-----------------+-------------+----------+---------+----------+----------+\n|Username| Identifier|One-time password|Recovery code|First name|Last name|Department|  Location|\n+--------+-----------+-----------------+-------------+----------+---------+----------+----------+\n|booker12|       9012|           12se74|       rb9012|    Rachel|   Booker|     Sales|Manchester|\n|  grey07|       2070|           04ap67|       lg2070|     Laura|     Grey|     Depot|    London|\n+--------+-----------+-----------------+-------------+----------+---------+----------+----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "email_df.show(2)\n",
    "dataset_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0278f78-c24e-4d5a-a648-a10794142db1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+------------+-----------+\n|    Login email_y|Identifier|First name_y|Last name_y|\n+-----------------+----------+------------+-----------+\n|laura@example.com|      2070|       Laura|       Grey|\n|craig@example.com|      4081|       Craig|    Johnson|\n+-----------------+----------+------------+-----------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "for col_name in email_df.columns:\n",
    "    if col_name != 'Identifier':\n",
    "        email_df = email_df.withColumnRenamed(col_name, f'{col_name}_y')\n",
    "email_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc099705-7a0c-4bf4-a6d3-be6ebc2757bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+\n| Username|One-time password|Recovery code|First name|Last name| Department|  Location|Identifier|      Login email|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+\n|   grey07|           04ap67|       lg2070|     Laura|     Grey|      Depot|    London|      2070|laura@example.com|\n|johnson81|           30no86|       cj4081|     Craig|  Johnson|      Depot|    London|      4081|craig@example.com|\n|jenkins46|           14ju73|       mj9346|      Mary|  Jenkins|Engineering|Manchester|      9346| mary@example.com|\n|  smith79|           09ja61|       js5079|     Jamie|    Smith|Engineering|Manchester|      5079|jamie@example.com|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "dataframe_joined = dataset_df.join(email_df.select('Identifier', 'Login email'), how='inner', on=(dataset_df[' Identifier'] == email_df['Identifier'])).drop(' Identifier')\n",
    "dataframe_joined.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72eca319-02a0-411e-b2ea-27c2d7e4a85a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- Username: string (nullable = true)\n |--  Identifier: integer (nullable = true)\n |-- One-time password: string (nullable = true)\n |-- Recovery code: string (nullable = true)\n |-- First name: string (nullable = true)\n |-- Last name: string (nullable = true)\n |-- Department: string (nullable = true)\n |-- Location: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "dataset_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "225665a2-cc96-4bb7-a143-c193187b1bfd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.na.fill({'Username': 'unknown' , '  Identifier': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e4e02c-f733-4116-b031-452cc395ff6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+\n| Username|One-time password|Recovery code|First name|Last name| Department|  Location|Identifier|      Login email|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+\n|   grey07|           04ap67|       lg2070|     Laura|     Grey|      Depot|    London|      2070|laura@example.com|\n|johnson81|           30no86|       cj4081|     Craig|  Johnson|      Depot|    London|      4081|craig@example.com|\n|jenkins46|           14ju73|       mj9346|      Mary|  Jenkins|Engineering|Manchester|      9346| mary@example.com|\n|  smith79|           09ja61|       js5079|     Jamie|    Smith|Engineering|Manchester|      5079|jamie@example.com|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "dataframe_joined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f140dfe-ab19-4932-aeb0-13a1bbaf812a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+-----+\n| Username|One-time password|Recovery code|First name|Last name| Department|  Location|Identifier|      Login email|Bonus|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+-----+\n|   grey07|           04ap67|       lg2070|     Laura|     Grey|      Depot|    London|      2070|laura@example.com|   10|\n|johnson81|           30no86|       cj4081|     Craig|  Johnson|      Depot|    London|      4081|craig@example.com|   10|\n|jenkins46|           14ju73|       mj9346|      Mary|  Jenkins|Engineering|Manchester|      9346| mary@example.com|   20|\n|  smith79|           09ja61|       js5079|     Jamie|    Smith|Engineering|Manchester|      5079|jamie@example.com|   20|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "dataframe_joined = dataframe_joined.withColumn(\n",
    "    \"Bonus\",\n",
    "    f.when(f.col(\"Department\") == \"Depot\", f.lit(10)).otherwise(\n",
    "        f.when(f.col(\"Department\") == \"Engineering\", f.lit(20)).otherwise(f.lit(1))\n",
    "    ),\n",
    ")\n",
    "dataframe_joined.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9de14cc3-6c1c-4581-b1fa-7f29b0885631",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cuadrado(Bonus):\n",
    "    resultado = Bonus * Bonus \n",
    "    return resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b454b08-c2c0-4c4e-bbb7-4d48ec94d1b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+-----+----------+\n| Username|One-time password|Recovery code|First name|Last name| Department|  Location|Identifier|      Login email|Bonus|Udf_Column|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+-----+----------+\n|   grey07|           04ap67|       lg2070|     Laura|     Grey|      Depot|    London|      2070|laura@example.com|   10|       100|\n|johnson81|           30no86|       cj4081|     Craig|  Johnson|      Depot|    London|      4081|craig@example.com|   10|       100|\n|jenkins46|           14ju73|       mj9346|      Mary|  Jenkins|Engineering|Manchester|      9346| mary@example.com|   20|       400|\n|  smith79|           09ja61|       js5079|     Jamie|    Smith|Engineering|Manchester|      5079|jamie@example.com|   20|       400|\n+---------+-----------------+-------------+----------+---------+-----------+----------+----------+-----------------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "cuadrado_udf = f.udf(cuadrado, IntegerType())\n",
    "dataframe_joined = dataframe_joined.withColumn('Udf_Column', cuadrado_udf(f.col('Bonus')))\n",
    "dataframe_joined.show()                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fe44ee7-84eb-4322-a7ad-3a6f9c579f45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2024-12-20 18:08:29",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
